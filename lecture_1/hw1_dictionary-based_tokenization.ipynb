{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"hw1_dictionary-based_tokenization.ipynb","provenance":[{"file_id":"1vB0n4NP0BRVPueJB1ICQt_uTvZclaXDz","timestamp":1610945416173},{"file_id":"1VBE3DFY6pZEk-sR2kuuq7VYqjfI7pDgV","timestamp":1610628767964}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"7EdbVSmE87En"},"source":["# HW1: Dictionary-based Tokenization \n"]},{"cell_type":"markdown","metadata":{"id":"pJJLm1Ub87Et"},"source":["In this exercise, you are to implement a dictionary-based word segmentation algorithm. There are two Python functions that you need to complete: \n","<br>\n","* maximal_matching\n","* backtrack\n","</br>\n","\n","Also, you have to find how to use word_tokenize() in PythaiNLP along with customer_dict by yourselves."]},{"cell_type":"markdown","metadata":{"id":"DF5Pme7CK3YF"},"source":["## Part1) Your Maximal Matching with Your Dictionary"]},{"cell_type":"markdown","metadata":{"id":"xzs0R06q87Et"},"source":["### Create a toy dictionary to test the algorithm\n","\n","This is based on the example shown in the lecture. \n","You will tokenize the following text string: \"ไปหามเหสี!\"\n","The toy dictoionary provided in this exercise includes all the charaters, syllables, and words that appear that the text string."]},{"cell_type":"code","metadata":{"id":"pq3W4p3z87Ev","executionInfo":{"status":"ok","timestamp":1610984841523,"user_tz":-420,"elapsed":858,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}}},"source":["thai_vocab = [\"ไ\",\"ป\",\"ห\",\"า\",\"ม\",\"เ\",\"ห\",\"ส\",\"ี\",\"ไป\",\"หา\",\"หาม\",\"เห\",\"สี\",\"มเหสี\",\"!\"]"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZornooGF87Ew"},"source":["### Maximal matching \n","Complete the maximal matching  function below to tokenize the input text\n"]},{"cell_type":"code","metadata":{"id":"Ao4d2E3387Ew","executionInfo":{"status":"ok","timestamp":1610984843109,"user_tz":-420,"elapsed":1427,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}}},"source":["from math import inf #infinity\n","\n","\n","def maximal_matching(c):\n","    #Initialize an empty 2D list\n","    d  =[[None]*len(c) for _ in range(len(c))]\n","    \n","    ####FILL CODE HERE####\n","    for i in range(len(c)):\n","      for j in range(i,len(c)):\n","        if i == 0 and j == 0 and c[i:j+1] in thai_vocab:\n","          d[i][j] = 1\n","        elif i == 0 and c[i:j+1] in thai_vocab:\n","          d[i][j] = 1\n","        elif c[i:j+1] in thai_vocab:\n","          temp = [d[r][i-1] for r in range(i)]\n","          d[i][j] = 1 + min([e for e in temp if e != None])\n","        else:\n","          d[i][j] = float('inf')\n","    ######################\n","    return d"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w7vBXfjM87Ew"},"source":["### Backtracking\n","Complete the backtracking function below to find the tokenzied words.\n","It should return a list containing a pair of the beginning position and the ending position of each word.\n","In this example, it should return: \n","<br>\n","[(0, 1),(2, 3),(4, 8),(9, 9)]\n","<br> \n","#### Each pair contains the position of each word as follows:\n","(0, 1) ไป\n","<br>\n","(2, 3) หา\n","<br>\n","(4, 8) มเหสี\n","<br>\n","(9, 9) !\n"]},{"cell_type":"code","metadata":{"id":"SxNFf1IE87Ex","executionInfo":{"status":"ok","timestamp":1610984843626,"user_tz":-420,"elapsed":1494,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}}},"source":["def min_pos(d,c):\n","    temp = [d[row][c] for row in range(c+1)]\n","    minimum = float('inf')\n","    minimum_pos = -1\n","    for i in range(len(temp)):\n","      if temp[i] < minimum:\n","        minimum = temp[i]\n","        minimum_pos = i\n","    return minimum_pos\n","\n","def backtrack(d):\n","    eow = len(d)-1 # End of Word position\n","    word_pos = [] # Word position\n","\n","    ####FILL CODE HERE####\n","    i = min_pos(d,eow)\n","    old_i = eow\n","    loop = True\n","    while loop:\n","      for j in range(i,-1,-1):\n","        if j == 0:\n","          word_pos.append((j,old_i))\n","          loop = False\n","          break\n","        elif d[i][j] == None:\n","          word_pos.append((j+1,old_i))\n","          old_i = i-1\n","          i = min_pos(d,j)\n","    ######################\n","    word_pos.reverse()\n","    return word_pos"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q0MJkKsh87Ex"},"source":["### Test your maximal matching algorithm on a toy dictionary\n","\n","Expected output:\n","\n","[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","<br>\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","<br>\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","<br>\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","<br>\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","<br>\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","<br>\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","<br>\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","<br>\n","[None, None, None, None, None, None, None, None, None, 4] !\n","<br>"]},{"cell_type":"code","metadata":{"id":"tsmVQIKS87Ey","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610984843627,"user_tz":-420,"elapsed":1116,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"d6bec650-5791-49f9-8f67-0b4fb13877a3"},"source":["input_text = \"ไปหามเหสี!\"\n","out = maximal_matching(input_text)\n","for i in range(len(out)):\n","    print(out[i],input_text[i])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","[None, None, None, None, None, None, None, None, None, 4] !\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IVhCMM4d87Ey"},"source":["### Test your backtracking algorithm on a toy dictionary\n","Expected output:\n","<br>\n","ไป|หา|มเหสี|!"]},{"cell_type":"code","metadata":{"id":"6Hurbm1f87Ey","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610984844003,"user_tz":-420,"elapsed":1112,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"ed3ca821-54d3-4f29-8207-43f1c9c44561"},"source":["def print_tokenized_text(d, input_text):\n","    tokenized_text=[]\n","    for pos in backtrack(d):\n","        #print(pos)\n","        tokenized_text.append(input_text[pos[0]:pos[1]+1])\n","\n","    print(\"|\".join(tokenized_text))\n","    \n","print_tokenized_text(out,input_text)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["ไป|หา|มเหสี|!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"57rP9cTU87Ez"},"source":["## Part2) Your Maximal Matching with Real Dictionary"]},{"cell_type":"markdown","metadata":{"id":"V306h7AG87Ez"},"source":["For UNIX-based OS users, the following cell will download a dictionary (it's just a list of thai words). Alternatively, you can download it from this link: https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"EFVR9LO187Ez","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610984846008,"user_tz":-420,"elapsed":1478,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"c4f36079-2203-45c6-cdf2-85efc52d82c8"},"source":["!wget https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"],"execution_count":7,"outputs":[{"output_type":"stream","text":["--2021-01-18 15:47:25--  https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1521600 (1.5M) [text/plain]\n","Saving to: ‘words_th.txt’\n","\n","words_th.txt        100%[===================>]   1.45M  --.-KB/s    in 0.09s   \n","\n","2021-01-18 15:47:25 (15.8 MB/s) - ‘words_th.txt’ saved [1521600/1521600]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nqIQzVgE87E0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610984846349,"user_tz":-420,"elapsed":916,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"4b9f7ff1-3b5c-4aa6-f863-1a3495df70d0"},"source":["with open(\"words_th.txt\",encoding='utf-8-sig') as f:\n","    thai_vocab = f.read().splitlines() \n","print(\"Vocab size:\", len(thai_vocab))\n","print(thai_vocab[:10])\n","\n","thai_vocab.extend([\"ๆ\",\"!\"])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Vocab size: 62143\n","['ก ข ไม่กระดิกหู', 'ก.', 'ก.ค.', 'ก.ต.', 'ก.ป.ส.', 'ก.พ.', 'ก.พ.ด.', 'ก.ม.', 'ก.ย.', 'ก.ย']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kpjwzw1w87E0"},"source":["### The output of your maximal matching algoithm on a new dictionary\n","Expected output:\n","<br>\n","[1, 1, 100000, 1, 100000, 100000, 100000, 100000, 100000] ไ\n","<br>\n","[None, 2, 100000, 100000, 100000, 100000, 100000, 100000, 100000] ป\n","<br>\n","[None, None, 2, 2, 2, 100000, 100000, 100000, 100000] ห\n","<br>\n","[None, None, None, 100000, 100000, 100000, 100000, 100000, 100000] า\n","<br>\n","[None, None, None, None, 2, 100000, 100000, 100000, 2] ม\n","<br>\n","[None, None, None, None, None, 100000, 3, 100000, 100000] เ\n","<br>\n","[None, None, None, None, None, None, 100001, 100000, 100000] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4] ส\n","<br>\n","[None, None, None, None, None, None, None, None, None] ี"]},{"cell_type":"code","metadata":{"id":"lYD5ChIS87E0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610984848780,"user_tz":-420,"elapsed":860,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"6d290f87-bdf4-48c2-c2f8-8265e8b02b9e"},"source":["input_text = \"ไปหามเหสี\"\n","out = maximal_matching(input_text)\n","for i in range(len(out)):\n","    print(out[i],input_text[i])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[inf, 1, inf, 1, inf, inf, inf, inf, inf] ไ\n","[None, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, inf, 2, 2, inf, inf, inf, inf] ห\n","[None, None, None, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, inf, inf, inf, inf, 2] ม\n","[None, None, None, None, None, inf, 3, inf, inf] เ\n","[None, None, None, None, None, None, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, inf, 4] ส\n","[None, None, None, None, None, None, None, None, inf] ี\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BSqLuK7G87E0"},"source":["### Expected tokenized text\n","ไปหา|มเหสี"]},{"cell_type":"code","metadata":{"id":"TI077jmy87E0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610984851334,"user_tz":-420,"elapsed":1117,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"94d2371f-5c14-4a09-a81c-aeb90b3cea45"},"source":["# print('ไปหา' in thai_vocab)\n","# print('มเหสี' in thai_vocab)\n","# print('ปปป' in thai_vocab)\n","print_tokenized_text(out,input_text)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["ไปหา|มเหสี\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VLGgO8PrLSz6"},"source":["## Part3) Maximal Matching from PythaiNLP"]},{"cell_type":"markdown","metadata":{"id":"LrZrzQoXLeUX"},"source":["### Default dictionary\n","\n","Study word_tokenize() from PythaiNLP in the link below.\n","\n","https://thainlp.org/pythainlp/docs/2.0/api/tokenize.html"]},{"cell_type":"code","metadata":{"id":"yXxPBOcNLXfm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610984879448,"user_tz":-420,"elapsed":25449,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"67ffb03e-fd73-47c7-b971-3f437742f4b5"},"source":["!pip install pythainlp\n","!pip install marisa_trie"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Collecting pythainlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/09/1215cb6f6ef0cfc9dbb427a961fda8a47c111955f782f659ca2d38c79adc/pythainlp-2.2.6-py3-none-any.whl (10.6MB)\n","\u001b[K     |████████████████████████████████| 10.6MB 3.7MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2.23.0)\n","Collecting tinydb>=3.0\n","  Downloading https://files.pythonhosted.org/packages/e5/7e/85ee672ee60affd5b4461efa19f260cf7575f36b94fbd1f0825742639910/tinydb-4.3.0-py3-none-any.whl\n","Collecting python-crfsuite>=0.9.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 51.7MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2020.12.5)\n","Installing collected packages: tinydb, python-crfsuite, pythainlp\n","Successfully installed pythainlp-2.2.6 python-crfsuite-0.9.7 tinydb-4.3.0\n","Collecting marisa_trie\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n","\u001b[K     |████████████████████████████████| 276kB 4.3MB/s \n","\u001b[?25hBuilding wheels for collected packages: marisa-trie\n","  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=862200 sha256=e7c62e4f98646bfd4b72cfa040f900a10f1b75e738d5a481af4a093b279483e2\n","  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n","Successfully built marisa-trie\n","Installing collected packages: marisa-trie\n","Successfully installed marisa-trie-0.7.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"goQE5gFUL4KO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610984881523,"user_tz":-420,"elapsed":26575,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"8287f7bc-9606-4047-8bd9-5a208eca3b6c"},"source":["from pythainlp.tokenize import word_tokenize\n","text='นัดกินกันตอนไหนก็ได้ที่สามย่านมิตรทาวน์'\n","\n","####FILL CODE HERE####\n","default_result = word_tokenize(text)\n","print(default_result)\n","######################"],"execution_count":12,"outputs":[{"output_type":"stream","text":["['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่าน', 'มิตร', 'ทาวน์']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2SlX5cEBMHPd"},"source":["### Custom dictionary\n","\n","Add 'สามย่านมิตรทาวน์' into dictionary and then tokenize again"]},{"cell_type":"code","metadata":{"id":"b4V9TqFaMPAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610984882745,"user_tz":-420,"elapsed":1218,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"b97eac03-f796-4224-f14d-e37195917e52"},"source":["####FILL CODE HERE####\n","from pythainlp.corpus.common import thai_words\n","import marisa_trie\n","\n","custom_dict = set(thai_words())\n","custom_dict.add(\"สามย่านมิตรทาวน์\")\n","trie = marisa_trie.Trie(custom_dict)\n","\n","custom_result = word_tokenize(text,custom_dict=trie)\n","print(custom_result)\n","######################"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่านมิตรทาวน์']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkqkG8fGLaVH","executionInfo":{"status":"ok","timestamp":1610984915488,"user_tz":-420,"elapsed":33959,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"d1feecb4-4896-4b9e-c394-2cc09889322e"},"source":["!pip install deepcut\n","!pip install PyICU"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: deepcut in /usr/local/lib/python3.6/dist-packages (0.7.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from deepcut) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepcut) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from deepcut) (2.10.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from deepcut) (1.4.1)\n","Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from deepcut) (2.4.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from deepcut) (0.22.2.post1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->deepcut) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepcut) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->deepcut) (1.15.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (0.3.3)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (2.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (3.12.4)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (3.7.4.3)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (1.1.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (1.1.2)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (0.36.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (1.12.1)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (0.2.0)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (2.4.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (1.6.3)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (1.32.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (1.12)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (0.10.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->deepcut) (3.3.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->deepcut) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.0.0->deepcut) (51.1.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (3.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.7.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (0.4.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.17.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (2.10)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (3.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (4.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (0.2.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (3.4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->deepcut) (0.4.8)\n","Collecting PyICU\n","  Using cached https://files.pythonhosted.org/packages/31/46/fa08c8efae2951e67681ec24319f789fc1a74e2096dd74373e34c79319de/PyICU-2.6.tar.gz\n","Building wheels for collected packages: PyICU\n","  Building wheel for PyICU (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyICU: filename=PyICU-2.6-cp36-cp36m-linux_x86_64.whl size=1288433 sha256=519927b3ae01b728236549ac9eb21e60ba2abb23ca4938782fc89732472321e2\n","  Stored in directory: /root/.cache/pip/wheels/31/21/2f/1c91831e8a93537ab21f6b4b935781b681104635fdb0315791\n","Successfully built PyICU\n","Installing collected packages: PyICU\n","Successfully installed PyICU-2.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C2Hd4krMa6sW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610985070323,"user_tz":-420,"elapsed":875,"user":{"displayName":"Pasit Laohawarutchai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjey2ogHq8KvxOVzzqfsVe8htC4Bjo5sdhAI1xJ=s64","userId":"06503996218411074564"}},"outputId":"afe01b27-575d-4e60-c25e-fc9d31770850"},"source":["# playing with different tokenize algorithms and compare.\n","print('Minimal Matching:',word_tokenize(text, engine='newmm'))\n","print('Longest:',word_tokenize(text, engine='longest'))\n","print('Deepcut:',word_tokenize(text, engine='deepcut'))\n","print('PyICU:',word_tokenize(text, engine='icu'))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Minimal Matching: ['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่าน', 'มิตร', 'ทาวน์']\n","Longest: ['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็ได้', 'ที่สาม', 'ย่าน', 'มิตร', 'ทาวน์']\n","Deepcut: ['นัด', 'กิน', 'กัน', 'ตอน', 'ไหน', 'ก็ได้', 'ที่', 'สาม', 'ย่าน', 'มิตรทาวน์']\n","PyICU: ['นัด', 'กิน', 'กัน', 'ตอน', 'ไหน', 'ก็ได้', 'ที่', 'สาม', 'ย่าน', 'มิตร', 'ทาวน์']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lg9twiXwLSkb"},"source":[""],"execution_count":null,"outputs":[]}]}