{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3_pos_tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppUxYJfnjh1W",
        "outputId": "ff5cf852-8a01-4207-ae6d-2294f0d00de7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Feb  2 06:51:41 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpCKO19dhHPq"
      },
      "source": [
        "# HW 3 - Neural POS Tagger\n",
        "\n",
        "In this exercise, you are going to build a set of deep learning models on part-of-speech (POS) tagging using Tensorflow 2. Tensorflow is a deep learning framwork developed by Google to provide an easier way to use standard layers and networks.\n",
        "\n",
        "To complete this exercise, you will need to build deep learning models for POS tagging in Thai using NECTEC's ORCHID corpus. You will build one model for each of the following type:\n",
        "\n",
        "- Neural POS Tagging with Word Embedding using Fixed / non-Fixed Pretrained weights\n",
        "- Neural POS Tagging with Viterbi / Marginal CRF\n",
        "\n",
        "Pretrained word embeddding are already given for you to use (albeit, a very bad one).\n",
        "\n",
        "We also provide the code for data cleaning, preprocessing and some starter code for tensorflow 2 in this notebook but feel free to modify those parts to suit your needs. Feel free to use additional libraries (e.g. scikit-learn) as long as you have a model for each type mentioned above.\n",
        "\n",
        "### Don't forget to change hardware accelrator to GPU in runtime on Google Colab ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx0YbM_8hHPt"
      },
      "source": [
        "## 1. Setup and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF3lPNNkhHPu"
      },
      "source": [
        "We use POS data from [ORCHID corpus](https://www.nectec.or.th/corpus/index.php?league=pm), which is a POS corpus for Thai language.\n",
        "A method used to read the corpus into a list of sentences with (word, POS) pairs have been implemented already. The example usage has shown below.\n",
        "We also create a word vector for unknown word by random."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS6O5yT6feRd"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58LvFz30zumq",
        "outputId": "a477eebd-3e5c-4281-f41c-c8a1f939b742"
      },
      "source": [
        "!wget https://www.dropbox.com/s/tuvrbsby4a5axe0/resources.zip\n",
        "!unzip resources.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-02 06:51:42--  https://www.dropbox.com/s/tuvrbsby4a5axe0/resources.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:601a:18::a27d:712\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/tuvrbsby4a5axe0/resources.zip [following]\n",
            "--2021-02-02 06:51:42--  https://www.dropbox.com/s/raw/tuvrbsby4a5axe0/resources.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc010e798bd177cbc3a199e8ddcf.dl.dropboxusercontent.com/cd/0/inline/BILDRpLpxR3EpKAC-tnbuOU7UMcrQPmA1e-KicqvG7IdNp1t0ioIwO300rohpn7joRdiB9s6_NwHEEInStYcicLL0OgYAICbZE2BpF0Z2rHrdg/file# [following]\n",
            "--2021-02-02 06:51:43--  https://uc010e798bd177cbc3a199e8ddcf.dl.dropboxusercontent.com/cd/0/inline/BILDRpLpxR3EpKAC-tnbuOU7UMcrQPmA1e-KicqvG7IdNp1t0ioIwO300rohpn7joRdiB9s6_NwHEEInStYcicLL0OgYAICbZE2BpF0Z2rHrdg/file\n",
            "Resolving uc010e798bd177cbc3a199e8ddcf.dl.dropboxusercontent.com (uc010e798bd177cbc3a199e8ddcf.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:601a:15::a27d:70f\n",
            "Connecting to uc010e798bd177cbc3a199e8ddcf.dl.dropboxusercontent.com (uc010e798bd177cbc3a199e8ddcf.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BILuBBHnKrQYjVE_qun_euobuIVPf5uo5yEfot5JwqA4ZLMVgQ2ijDJMFzC9ElFWcyp6jXBDX6dSDv-rxFeTgrURG4jzq1mm-15rJyku1pZejdjbH4riv2Keq-8JYYay1HEY79V2aHw-PcSgGC06Xl9Iv4mmQAyfk7pSrqetWxDTWJ1Gjn-stazzslCbuFOcIXSpb-BA6mMia26FwXZ-AJZIlohlfy9muq8omDFVIFPwM6ADSa2OdOmTLAm29e3GWzEJHFUPlae5A-Xhc-dFZDzWBpZNIOtj0nogtiuKDlRYQKUbuU7JjZGd6Yh-FnNr9bcdh4JhhpGdmrUI6Eba0-Vy/file [following]\n",
            "--2021-02-02 06:51:43--  https://uc010e798bd177cbc3a199e8ddcf.dl.dropboxusercontent.com/cd/0/inline2/BILuBBHnKrQYjVE_qun_euobuIVPf5uo5yEfot5JwqA4ZLMVgQ2ijDJMFzC9ElFWcyp6jXBDX6dSDv-rxFeTgrURG4jzq1mm-15rJyku1pZejdjbH4riv2Keq-8JYYay1HEY79V2aHw-PcSgGC06Xl9Iv4mmQAyfk7pSrqetWxDTWJ1Gjn-stazzslCbuFOcIXSpb-BA6mMia26FwXZ-AJZIlohlfy9muq8omDFVIFPwM6ADSa2OdOmTLAm29e3GWzEJHFUPlae5A-Xhc-dFZDzWBpZNIOtj0nogtiuKDlRYQKUbuU7JjZGd6Yh-FnNr9bcdh4JhhpGdmrUI6Eba0-Vy/file\n",
            "Reusing existing connection to uc010e798bd177cbc3a199e8ddcf.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 151484222 (144M) [application/zip]\n",
            "Saving to: ‘resources.zip’\n",
            "\n",
            "resources.zip       100%[===================>] 144.47M  66.8MB/s    in 2.2s    \n",
            "\n",
            "2021-02-02 06:51:46 (66.8 MB/s) - ‘resources.zip’ saved [151484222/151484222]\n",
            "\n",
            "Archive:  resources.zip\n",
            "  inflating: basic_ff_embedding.pt   \n",
            "   creating: data/\n",
            " extracting: data/__init__.py        \n",
            "  inflating: data/__init__.pyc       \n",
            "   creating: data/__pycache__/\n",
            "  inflating: data/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: data/__pycache__/orchid_corpus.cpython-36.pyc  \n",
            "  inflating: data/orchid97.txt       \n",
            "  inflating: data/orchid_corpus.py   \n",
            "  inflating: data/orchid_corpus.pyc  \n",
            "  inflating: data/orchid_test.txt    \n",
            "  inflating: data/orchid_train.txt   \n",
            "   creating: embeddings/\n",
            " extracting: embeddings/__init__.py  \n",
            "   creating: embeddings/__pycache__/\n",
            "  inflating: embeddings/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: embeddings/__pycache__/emb_reader.cpython-36.pyc  \n",
            "  inflating: embeddings/emb_reader.py  \n",
            "  inflating: embeddings/polyglot-th.pkl  \n",
            "   creating: model/\n",
            "  inflating: model/_DS_Store         \n",
            "  inflating: model/crf_basic.model   \n",
            "  inflating: model/crf_neural.model  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2a9b92hYTg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a786ae77-cfb9-4816-c55d-16a9e97608d3"
      },
      "source": [
        "!pip install python-crfsuite\n",
        "!pip install tensorflow-addons\n",
        "!pip install tf2crf"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-crfsuite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\r\u001b[K     |▍                               | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 14.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 12.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 12.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 9.0MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 9.8MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 245kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 266kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 276kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 286kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 481kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 491kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 501kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 522kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 532kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 542kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 552kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 563kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 573kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 583kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 716kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 727kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 737kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 747kB 8.2MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Collecting tf2crf\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f5/e9f972be845a2b0ea93c76d26ed6b7bde599a48f70554a30a528117731c8/tf2crf-0.1.29-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow-addons>=0.8.2 in /usr/local/lib/python3.6/dist-packages (from tf2crf) (0.8.3)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tf2crf) (2.4.1)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons>=0.8.2->tf2crf) (2.7.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.12.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.10.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.7.4.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.3.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.19.5)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.6.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (51.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (0.2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.1.0)\n",
            "Installing collected packages: tf2crf\n",
            "Successfully installed tf2crf-0.1.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c7upY0fYsdt"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJpCbSvJhHPv"
      },
      "source": [
        "from data.orchid_corpus import get_sentences\n",
        "import numpy as np\n",
        "import numpy.random\n",
        "import tensorflow as tf\n",
        "np.random.seed(42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4SZz56ThHP0",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499ea69c-eba8-40a1-e438-8b177dd9c7fc"
      },
      "source": [
        "yunk_emb =np.random.randn(32)\n",
        "train_data = get_sentences('train')\n",
        "test_data = get_sentences('test')\n",
        "print(train_data[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('การ', 'FIXN'), ('ประชุม', 'VACT'), ('ทาง', 'NCMN'), ('วิชาการ', 'NCMN'), ('<space>', 'PUNC'), ('ครั้ง', 'CFQC'), ('ที่ 1', 'DONM')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awxn_GRIhHP3"
      },
      "source": [
        "Next, we load pretrained weight embedding using pickle. The pretrained weight is a dictionary which map a word to its embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GS3lTZshHP4"
      },
      "source": [
        "import pickle\n",
        "fp = open('basic_ff_embedding.pt', 'rb')\n",
        "embeddings = pickle.load(fp)\n",
        "fp.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CqTNKsChHP7"
      },
      "source": [
        "The given code below generates an indexed dataset(each word is represented by a number) for training and testing data. The index 0 is reserved for padding to help with variable length sequence. (Additionally, You can read more about padding here [https://machinelearningmastery.com/data-preparation-variable-length-input-sequences-sequence-prediction/])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPGUNEZyhHP8"
      },
      "source": [
        "## 2. Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fMWn8qehHP9"
      },
      "source": [
        "word_to_idx ={}\n",
        "idx_to_word ={}\n",
        "label_to_idx = {}\n",
        "for sentence in train_data:\n",
        "    for word,pos in sentence:\n",
        "        if word not in word_to_idx:\n",
        "            word_to_idx[word] = len(word_to_idx)+1\n",
        "            idx_to_word[word_to_idx[word]] = word\n",
        "        if pos not in label_to_idx:\n",
        "            label_to_idx[pos] = len(label_to_idx)+1\n",
        "word_to_idx['UNK'] = len(word_to_idx)\n",
        "\n",
        "n_classes = len(label_to_idx.keys())+1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgvZ8v_2hHP_"
      },
      "source": [
        "This section is tweaked a little from the demo, word2features will return word index instead of features, and sent2labels will return a sequence of word indices in the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktf2KkJghHQA"
      },
      "source": [
        "def word2features(sent, i, emb):\n",
        "    word = sent[i][0]\n",
        "    if word in word_to_idx :\n",
        "        return word_to_idx[word]\n",
        "    else :\n",
        "        return word_to_idx['UNK']\n",
        "\n",
        "def sent2features(sent, emb_dict):\n",
        "    return np.asarray([word2features(sent, i, emb_dict) for i in range(len(sent))])\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return numpy.asarray([label_to_idx[label] for (word, label) in sent],dtype='int32')\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [word for (word, label) in sent]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgBw3I9ShHQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc171d90-ca4b-4f6c-c3cb-eb00ebc8096f"
      },
      "source": [
        "sent2features(train_data[100], embeddings)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 29, 327,   5, 328])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O7oClK-hHQG"
      },
      "source": [
        "Next we create train and test dataset, then we use tensorflow 2 to post-pad the sequence to max sequence with 0. Our labels are changed to a one-hot vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tJxtPtohHQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90eec98-a8c2-4a01-d8f9-31f6e3c21e2c"
      },
      "source": [
        "%%time\n",
        "x_train = np.asarray([sent2features(sent, embeddings) for sent in train_data])\n",
        "y_train = [sent2labels(sent) for sent in train_data]\n",
        "x_test = [sent2features(sent, embeddings) for sent in test_data]\n",
        "y_test = [sent2labels(sent) for sent in test_data]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 378 ms, sys: 1.56 ms, total: 380 ms\n",
            "Wall time: 386 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG1gvJ4mhHQJ"
      },
      "source": [
        "x_train=tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=None, dtype='int32', padding='post', truncating='pre', value=0.)\n",
        "y_train=tf.keras.preprocessing.sequence.pad_sequences(y_train, maxlen=None, dtype='int32', padding='post', truncating='pre', value=0.)\n",
        "x_test=tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=102, dtype='int32', padding='post', truncating='pre', value=0.)\n",
        "y_temp =[]\n",
        "for i in range(len(y_train)):\n",
        "    y_temp.append(np.eye(n_classes)[y_train[i]][np.newaxis,:])\n",
        "y_train = np.asarray(y_temp).reshape(-1,102,n_classes)\n",
        "del(y_temp)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU9x6VdehHQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d95b5f-6988-430c-96f5-b7f7bacc0729"
      },
      "source": [
        "print(x_train[100],x_train.shape)\n",
        "print(y_train[100][3],y_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 29 327   5 328   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0] (18500, 102)\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] (18500, 102, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx_c3-LwhHQP"
      },
      "source": [
        "## 3. Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvCW24orhHQP"
      },
      "source": [
        "Our output from tf keras is a distribution of problabilities on all possible label. outputToLabel will return an indices of maximum problability from output sequence.\n",
        "\n",
        "evaluation_report is the same as in the demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqgp2gd4hHQQ"
      },
      "source": [
        "def outputToLabel(yt,seq_len):\n",
        "    out = []\n",
        "    for i in range(0,len(yt)):\n",
        "        if(i==seq_len):\n",
        "            break\n",
        "        out.append(np.argmax(yt[i]))\n",
        "    return out"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzIL_rsAhHQT"
      },
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "def evaluation_report(y_true, y_pred):\n",
        "    # retrieve all tags in y_true\n",
        "    tag_set = set()\n",
        "    for sent in y_true:\n",
        "        for tag in sent:\n",
        "            tag_set.add(tag)\n",
        "    for sent in y_pred:\n",
        "        for tag in sent:\n",
        "            tag_set.add(tag)\n",
        "    tag_list = sorted(list(tag_set))\n",
        "    \n",
        "    # count correct points\n",
        "    tag_info = dict()\n",
        "    for tag in tag_list:\n",
        "        tag_info[tag] = {'correct_tagged': 0, 'y_true': 0, 'y_pred': 0}\n",
        "\n",
        "    all_correct = 0\n",
        "    all_count = sum([len(sent) for sent in y_true])\n",
        "    for sent_true, sent_pred in zip(y_true, y_pred):\n",
        "        for tag_true, tag_pred in zip(sent_true, sent_pred):\n",
        "            if tag_true == tag_pred:\n",
        "                tag_info[tag_true]['correct_tagged'] += 1\n",
        "                all_correct += 1\n",
        "            tag_info[tag_true]['y_true'] += 1\n",
        "            tag_info[tag_pred]['y_pred'] += 1\n",
        "    accuracy = (all_correct / all_count) * 100\n",
        "            \n",
        "    # summarize and make evaluation result\n",
        "    eval_list = list()\n",
        "    for tag in tag_list:\n",
        "        eval_result = dict()\n",
        "        eval_result['tag'] = tag\n",
        "        eval_result['correct_count'] = tag_info[tag]['correct_tagged']\n",
        "        precision = (tag_info[tag]['correct_tagged']/tag_info[tag]['y_pred'])*100 if tag_info[tag]['y_pred'] else '-'\n",
        "        recall = (tag_info[tag]['correct_tagged']/tag_info[tag]['y_true'])*100 if (tag_info[tag]['y_true'] > 0) else 0\n",
        "        eval_result['precision'] = precision\n",
        "        eval_result['recall'] = recall\n",
        "        eval_result['f_score'] = (2*precision*recall)/(precision+recall) if (type(precision) is float and recall > 0) else '-'\n",
        "        \n",
        "        eval_list.append(eval_result)\n",
        "\n",
        "    eval_list.append({'tag': 'accuracy=%.2f' % accuracy, 'correct_count': '', 'precision': '', 'recall': '', 'f_score': ''})\n",
        "    \n",
        "    df = pd.DataFrame.from_dict(eval_list)\n",
        "    df = df[['tag', 'precision', 'recall', 'f_score', 'correct_count']]\n",
        "    display(df)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YG-RiHdhHQV"
      },
      "source": [
        "## 4. Train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HrkAiMFhHQW"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input, Dense,GRU,Reshape,TimeDistributed,Bidirectional,Dropout,Masking\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U75Ivn2vhHQZ"
      },
      "source": [
        "The model is this section is separated to two groups\n",
        "\n",
        "- Neural POS Tagger (4.1)\n",
        "- Neural CRF POS Tagger (4.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLwL3B7rhHQZ"
      },
      "source": [
        "## 4.1.1 Neural POS Tagger  (Example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVoB-1XVhHQa"
      },
      "source": [
        "We create a simple Neural POS Tagger as an example for you. This model dosen't use any pretrained word embbeding so it need to use Embedding layer to train the word embedding from scratch.\n",
        "\n",
        "Instead of using tensorflow.keras.models.Sequential, we use tensorflow.keras.models.Model. The latter is better as it can have multiple input/output, of which Sequential model could not. Due to this reason, the Model class is widely used for building a complex deep learning model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxBvv9qfhHQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee74a36-8705-46a8-d1f2-1f18d9c36b48"
      },
      "source": [
        "inputs = Input(shape=(102,), dtype='int32')\n",
        "output = (Embedding(len(word_to_idx),32,input_length=102,mask_zero=True))(inputs)\n",
        "output = Bidirectional(GRU(32, return_sequences=True))(output)\n",
        "output = Dropout(0.2)(output)\n",
        "output = TimeDistributed(Dense(n_classes,activation='softmax'))(output)\n",
        "model = Model(inputs, output)\n",
        "model.compile(optimizer=Adam(lr=0.001),  loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n",
        "model.fit(x_train,y=y_train, batch_size=64,epochs=10,verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 102)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 102, 32)           480608    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 102, 64)           12672     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 102, 64)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 102, 48)           3120      \n",
            "=================================================================\n",
            "Total params: 496,400\n",
            "Trainable params: 496,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "290/290 [==============================] - 21s 25ms/step - loss: 0.3940 - categorical_accuracy: 0.3876\n",
            "Epoch 2/10\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0712 - categorical_accuracy: 0.8888\n",
            "Epoch 3/10\n",
            "290/290 [==============================] - 7s 25ms/step - loss: 0.0404 - categorical_accuracy: 0.9278\n",
            "Epoch 4/10\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0303 - categorical_accuracy: 0.9427\n",
            "Epoch 5/10\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0267 - categorical_accuracy: 0.9482\n",
            "Epoch 6/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0235 - categorical_accuracy: 0.9536\n",
            "Epoch 7/10\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0219 - categorical_accuracy: 0.9558\n",
            "Epoch 8/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0206 - categorical_accuracy: 0.9572\n",
            "Epoch 9/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0194 - categorical_accuracy: 0.9601\n",
            "Epoch 10/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0188 - categorical_accuracy: 0.9606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1c8d867b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo9Da8MThHQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59478c83-317c-4464-9215-ec407ba8a070"
      },
      "source": [
        "%%time\n",
        "model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0180 - categorical_accuracy: 0.9618\n",
            "Epoch 2/10\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0174 - categorical_accuracy: 0.9629\n",
            "Epoch 3/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0167 - categorical_accuracy: 0.9643\n",
            "Epoch 4/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0161 - categorical_accuracy: 0.9657\n",
            "Epoch 5/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0155 - categorical_accuracy: 0.9668\n",
            "Epoch 6/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0150 - categorical_accuracy: 0.9677\n",
            "Epoch 7/10\n",
            "290/290 [==============================] - 7s 26ms/step - loss: 0.0145 - categorical_accuracy: 0.9688\n",
            "Epoch 8/10\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0140 - categorical_accuracy: 0.9697\n",
            "Epoch 9/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0135 - categorical_accuracy: 0.9708\n",
            "Epoch 10/10\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.0131 - categorical_accuracy: 0.9718\n",
            "CPU times: user 1min 32s, sys: 16 s, total: 1min 48s\n",
            "Wall time: 1min 9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1e1b9f128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yusa214hhHQh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1342baeb-474a-412f-de0c-be641822d29b"
      },
      "source": [
        "%%time\n",
        "model.save_weights('./data/my_pos_no_crf.h5')\n",
        "#model.load_weights('./data/my_pos_no_crf.h5')\n",
        "y_pred=model.predict(x_test)\n",
        "ypred = [outputToLabel(y_pred[i],len(y_test[i])) for i in range(len(y_pred))]\n",
        "evaluation_report(y_test, ypred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f_score</th>\n",
              "      <th>correct_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>99.891</td>\n",
              "      <td>99.4844</td>\n",
              "      <td>99.6873</td>\n",
              "      <td>3666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>95.297</td>\n",
              "      <td>93.356</td>\n",
              "      <td>94.3165</td>\n",
              "      <td>7700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>91.2757</td>\n",
              "      <td>95.275</td>\n",
              "      <td>93.2325</td>\n",
              "      <td>16091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>99.9302</td>\n",
              "      <td>99.644</td>\n",
              "      <td>99.7869</td>\n",
              "      <td>12876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>88</td>\n",
              "      <td>98.5075</td>\n",
              "      <td>92.9577</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>98.1481</td>\n",
              "      <td>91.3793</td>\n",
              "      <td>94.6429</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>97.4359</td>\n",
              "      <td>96.8735</td>\n",
              "      <td>97.1539</td>\n",
              "      <td>2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>76.4706</td>\n",
              "      <td>53.253</td>\n",
              "      <td>62.7841</td>\n",
              "      <td>221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>50.5376</td>\n",
              "      <td>63.8587</td>\n",
              "      <td>56.4226</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>61.9454</td>\n",
              "      <td>43.2658</td>\n",
              "      <td>50.9474</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>60.1399</td>\n",
              "      <td>100</td>\n",
              "      <td>75.1092</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>93.8406</td>\n",
              "      <td>97.0037</td>\n",
              "      <td>95.3959</td>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>88.9784</td>\n",
              "      <td>86.0323</td>\n",
              "      <td>87.4805</td>\n",
              "      <td>3092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>93.5863</td>\n",
              "      <td>95.7005</td>\n",
              "      <td>94.6316</td>\n",
              "      <td>5253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>82.0459</td>\n",
              "      <td>70.0535</td>\n",
              "      <td>75.5769</td>\n",
              "      <td>786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>89.8172</td>\n",
              "      <td>85.9284</td>\n",
              "      <td>87.8298</td>\n",
              "      <td>2064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>97.037</td>\n",
              "      <td>89.726</td>\n",
              "      <td>93.2384</td>\n",
              "      <td>524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>97.7872</td>\n",
              "      <td>99.4805</td>\n",
              "      <td>98.6266</td>\n",
              "      <td>1149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>98.5207</td>\n",
              "      <td>96.5217</td>\n",
              "      <td>97.511</td>\n",
              "      <td>333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>96.6216</td>\n",
              "      <td>96.9492</td>\n",
              "      <td>96.7851</td>\n",
              "      <td>286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>95.8728</td>\n",
              "      <td>93.5314</td>\n",
              "      <td>94.6876</td>\n",
              "      <td>1417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>81.0345</td>\n",
              "      <td>82.0961</td>\n",
              "      <td>81.5618</td>\n",
              "      <td>1316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>89.0751</td>\n",
              "      <td>94.1885</td>\n",
              "      <td>91.5605</td>\n",
              "      <td>1329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>87.1823</td>\n",
              "      <td>86.2295</td>\n",
              "      <td>86.7033</td>\n",
              "      <td>789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>83.2402</td>\n",
              "      <td>72.155</td>\n",
              "      <td>77.3022</td>\n",
              "      <td>298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>84.7368</td>\n",
              "      <td>91.4773</td>\n",
              "      <td>87.9781</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>93.913</td>\n",
              "      <td>82.4427</td>\n",
              "      <td>87.8049</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>29</td>\n",
              "      <td>93.6364</td>\n",
              "      <td>97.7848</td>\n",
              "      <td>95.6656</td>\n",
              "      <td>309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>30</td>\n",
              "      <td>76</td>\n",
              "      <td>74.5098</td>\n",
              "      <td>75.2475</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>31</td>\n",
              "      <td>59.3103</td>\n",
              "      <td>83.4951</td>\n",
              "      <td>69.3548</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>32</td>\n",
              "      <td>58.7912</td>\n",
              "      <td>60.1124</td>\n",
              "      <td>59.4444</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>33</td>\n",
              "      <td>81.3953</td>\n",
              "      <td>51.4706</td>\n",
              "      <td>63.0631</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>34</td>\n",
              "      <td>93.1298</td>\n",
              "      <td>86.8327</td>\n",
              "      <td>89.8711</td>\n",
              "      <td>488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>35</td>\n",
              "      <td>50</td>\n",
              "      <td>55.5556</td>\n",
              "      <td>52.6316</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>36</td>\n",
              "      <td>100</td>\n",
              "      <td>62.5</td>\n",
              "      <td>76.9231</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>37</td>\n",
              "      <td>90.991</td>\n",
              "      <td>99.0196</td>\n",
              "      <td>94.8357</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>38</td>\n",
              "      <td>59.375</td>\n",
              "      <td>48.7179</td>\n",
              "      <td>53.5211</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>39</td>\n",
              "      <td>70.7602</td>\n",
              "      <td>86.4286</td>\n",
              "      <td>77.8135</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>40</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>41</td>\n",
              "      <td>88.8889</td>\n",
              "      <td>80</td>\n",
              "      <td>84.2105</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>42</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>43</td>\n",
              "      <td>42.8571</td>\n",
              "      <td>33.3333</td>\n",
              "      <td>37.5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>45</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>46</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>accuracy=93.02</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               tag precision   recall  f_score correct_count\n",
              "0                1    99.891  99.4844  99.6873          3666\n",
              "1                2    95.297   93.356  94.3165          7700\n",
              "2                3   91.2757   95.275  93.2325         16091\n",
              "3                4   99.9302   99.644  99.7869         12876\n",
              "4                5        88  98.5075  92.9577            66\n",
              "5                6   98.1481  91.3793  94.6429           477\n",
              "6                7   97.4359  96.8735  97.1539          2014\n",
              "7                8   76.4706   53.253  62.7841           221\n",
              "8                9   50.5376  63.8587  56.4226           235\n",
              "9               10   61.9454  43.2658  50.9474           363\n",
              "10              11   60.1399      100  75.1092            86\n",
              "11              12   93.8406  97.0037  95.3959           777\n",
              "12              13   88.9784  86.0323  87.4805          3092\n",
              "13              14   93.5863  95.7005  94.6316          5253\n",
              "14              15   82.0459  70.0535  75.5769           786\n",
              "15              16   89.8172  85.9284  87.8298          2064\n",
              "16              17    97.037   89.726  93.2384           524\n",
              "17              18   97.7872  99.4805  98.6266          1149\n",
              "18              19   98.5207  96.5217   97.511           333\n",
              "19              20   96.6216  96.9492  96.7851           286\n",
              "20              21   95.8728  93.5314  94.6876          1417\n",
              "21              22   81.0345  82.0961  81.5618          1316\n",
              "22              23   89.0751  94.1885  91.5605          1329\n",
              "23              24   87.1823  86.2295  86.7033           789\n",
              "24              25   83.2402   72.155  77.3022           298\n",
              "25              26   84.7368  91.4773  87.9781           161\n",
              "26              27    93.913  82.4427  87.8049           108\n",
              "27              29   93.6364  97.7848  95.6656           309\n",
              "28              30        76  74.5098  75.2475            76\n",
              "29              31   59.3103  83.4951  69.3548            86\n",
              "30              32   58.7912  60.1124  59.4444           107\n",
              "31              33   81.3953  51.4706  63.0631            35\n",
              "32              34   93.1298  86.8327  89.8711           488\n",
              "33              35        50  55.5556  52.6316             5\n",
              "34              36       100     62.5  76.9231            10\n",
              "35              37    90.991  99.0196  94.8357           101\n",
              "36              38    59.375  48.7179  53.5211            19\n",
              "37              39   70.7602  86.4286  77.8135           121\n",
              "38              40       100      100      100           280\n",
              "39              41   88.8889       80  84.2105            16\n",
              "40              42       100      100      100            17\n",
              "41              43   42.8571  33.3333     37.5             3\n",
              "42              45         -        0        -             0\n",
              "43              46         -        0        -             0\n",
              "44  accuracy=93.02                                          "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.87 s, sys: 196 ms, total: 4.07 s\n",
            "Wall time: 3.71 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0NKka14hHQw"
      },
      "source": [
        "## 4.2 CRF Viterbi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijd1rwTghHQx"
      },
      "source": [
        "Your next task is to incorporate Conditional random fields (CRF) to your model.\n",
        "\n",
        "To use the CRF layer, you need to use an extension repository for tensorflow library, call tf2crf. If you want to see the detailed implementation, you should read the official tensorflow extention of CRF (https://www.tensorflow.org/addons/api_docs/python/tfa/text).\n",
        "\n",
        "tf2crf link :  https://github.com/xuxingya/tf2crf\n",
        "\n",
        "For inference, you should look at crf.py at the method call and view the input/output argmunets. \n",
        "Link : https://github.com/xuxingya/tf2crf/blob/master/tf2crf/crf.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuybajePhHQy"
      },
      "source": [
        "### 4.2.1 CRF without pretrained weight\n",
        "### #TODO 1\n",
        "Incoperate CRF layer to your model in 4.1. CRF is quite complex compare to previous example model, so you should train it with more epoch, so it can converge.\n",
        "\n",
        "To finish this excercise you must train the model and show the evaluation report with this model as shown in the example.\n",
        "\n",
        "Do not forget to save this model weight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT-t7A0GXPNT"
      },
      "source": [
        "from tf2crf import CRF, ModelWithCRFLoss"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEV0q1vAhHQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d5f329-2cdc-4e1a-b758-f0eb8c03b8b7"
      },
      "source": [
        "# INSERT YOUR CODE HERE\n",
        "\n",
        "inputs = Input(shape=(102,), dtype='int32')\n",
        "output = (Embedding(len(word_to_idx),32,input_length=102,mask_zero=True))(inputs)\n",
        "output = Bidirectional(GRU(32, return_sequences=True))(output)\n",
        "output = Dropout(0.2)(output)\n",
        "output = TimeDistributed(Dense(n_classes, activation=None))(output)\n",
        "crf = CRF(dtype='float32')\n",
        "output = crf(output)\n",
        "base_model = Model(inputs, output)\n",
        "model_crf = ModelWithCRFLoss(base_model)\n",
        "model_crf.compile(optimizer=Adam(lr=0.001))\n",
        "\n",
        "model_crf.build((102,1))\n",
        "model_crf.summary()\n",
        "model_crf.fit(x=x_train,y=y_train.argmax(axis=2), batch_size=64,epochs=10,verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 102) for input KerasTensor(type_spec=TensorSpec(shape=(None, 102), dtype=tf.int32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (102, 1).\n",
            "Model: \"model_with_crf_loss_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_4 (Functional)         ((None, 102), (None, 102, 498706    \n",
            "=================================================================\n",
            "Total params: 498,708\n",
            "Trainable params: 498,704\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "290/290 [==============================] - 111s 345ms/step - crf_loss: 25.6719 - accuracy: 0.5722\n",
            "Epoch 2/10\n",
            "290/290 [==============================] - 99s 341ms/step - crf_loss: 5.7208 - accuracy: 0.9088\n",
            "Epoch 3/10\n",
            "290/290 [==============================] - 99s 340ms/step - crf_loss: 3.5697 - accuracy: 0.9372\n",
            "Epoch 4/10\n",
            "290/290 [==============================] - 99s 342ms/step - crf_loss: 2.8536 - accuracy: 0.9469\n",
            "Epoch 5/10\n",
            "290/290 [==============================] - 98s 340ms/step - crf_loss: 2.4877 - accuracy: 0.9523\n",
            "Epoch 6/10\n",
            "290/290 [==============================] - 98s 340ms/step - crf_loss: 2.2528 - accuracy: 0.9556\n",
            "Epoch 7/10\n",
            "290/290 [==============================] - 98s 338ms/step - crf_loss: 2.1030 - accuracy: 0.9575\n",
            "Epoch 8/10\n",
            "290/290 [==============================] - 100s 344ms/step - crf_loss: 1.9836 - accuracy: 0.9591\n",
            "Epoch 9/10\n",
            "290/290 [==============================] - 97s 333ms/step - crf_loss: 1.8977 - accuracy: 0.9609\n",
            "Epoch 10/10\n",
            "290/290 [==============================] - 97s 336ms/step - crf_loss: 1.8070 - accuracy: 0.9624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1dc421710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq5nMXwd-3U-",
        "outputId": "c069472f-d2c7-4acc-98d5-d30bd9b94864"
      },
      "source": [
        "model_crf.fit(x=x_train,y=y_train.argmax(axis=2), batch_size=64,epochs=10,verbose=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "290/290 [==============================] - 98s 337ms/step - crf_loss: 1.7343 - accuracy: 0.9636\n",
            "Epoch 2/10\n",
            "290/290 [==============================] - 97s 334ms/step - crf_loss: 1.6694 - accuracy: 0.9647\n",
            "Epoch 3/10\n",
            "290/290 [==============================] - 99s 342ms/step - crf_loss: 1.6057 - accuracy: 0.9659\n",
            "Epoch 4/10\n",
            "290/290 [==============================] - 98s 337ms/step - crf_loss: 1.5685 - accuracy: 0.9670\n",
            "Epoch 5/10\n",
            "290/290 [==============================] - 99s 341ms/step - crf_loss: 1.4907 - accuracy: 0.9683\n",
            "Epoch 6/10\n",
            "290/290 [==============================] - 98s 339ms/step - crf_loss: 1.4432 - accuracy: 0.9693\n",
            "Epoch 7/10\n",
            "290/290 [==============================] - 98s 338ms/step - crf_loss: 1.3958 - accuracy: 0.9702\n",
            "Epoch 8/10\n",
            "290/290 [==============================] - 99s 343ms/step - crf_loss: 1.3527 - accuracy: 0.9715\n",
            "Epoch 9/10\n",
            "290/290 [==============================] - 97s 336ms/step - crf_loss: 1.2911 - accuracy: 0.9722\n",
            "Epoch 10/10\n",
            "290/290 [==============================] - 98s 339ms/step - crf_loss: 1.2659 - accuracy: 0.9734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1e00484a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eVhhhD8HG9VH",
        "outputId": "c413b0d7-f1d8-49e5-9256-0fb614fd6de5"
      },
      "source": [
        "%%time\n",
        "model_crf.save_weights('./data/my_pos_crf.h5')\n",
        "# model_crf.load_weights('./data/my_pos_crf.h5')\n",
        "y_pred=model_crf.predict(x_test)[1]\n",
        "ypred = [outputToLabel(y_pred[i],len(y_test[i])) for i in range(len(y_pred))]\n",
        "evaluation_report(y_test, ypred)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f_score</th>\n",
              "      <th>correct_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>99.8641</td>\n",
              "      <td>99.7015</td>\n",
              "      <td>99.7827</td>\n",
              "      <td>3674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>94.681</td>\n",
              "      <td>94.0955</td>\n",
              "      <td>94.3874</td>\n",
              "      <td>7761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90.7904</td>\n",
              "      <td>96.3704</td>\n",
              "      <td>93.4972</td>\n",
              "      <td>16276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>99.9146</td>\n",
              "      <td>99.644</td>\n",
              "      <td>99.7791</td>\n",
              "      <td>12876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>91.6667</td>\n",
              "      <td>98.5075</td>\n",
              "      <td>94.964</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>99.1561</td>\n",
              "      <td>90.0383</td>\n",
              "      <td>94.3775</td>\n",
              "      <td>470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>97.6654</td>\n",
              "      <td>96.5849</td>\n",
              "      <td>97.1221</td>\n",
              "      <td>2008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>76.5957</td>\n",
              "      <td>52.0482</td>\n",
              "      <td>61.9799</td>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>58.7302</td>\n",
              "      <td>60.3261</td>\n",
              "      <td>59.5174</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>61.8214</td>\n",
              "      <td>42.0739</td>\n",
              "      <td>50.0709</td>\n",
              "      <td>353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>80.3738</td>\n",
              "      <td>100</td>\n",
              "      <td>89.1192</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>95.0182</td>\n",
              "      <td>97.628</td>\n",
              "      <td>96.3054</td>\n",
              "      <td>782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>89.1701</td>\n",
              "      <td>84.3072</td>\n",
              "      <td>86.6705</td>\n",
              "      <td>3030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>93.4845</td>\n",
              "      <td>94.6256</td>\n",
              "      <td>94.0516</td>\n",
              "      <td>5194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>80.5031</td>\n",
              "      <td>68.4492</td>\n",
              "      <td>73.9884</td>\n",
              "      <td>768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>90.031</td>\n",
              "      <td>84.5962</td>\n",
              "      <td>87.229</td>\n",
              "      <td>2032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>96.4158</td>\n",
              "      <td>92.1233</td>\n",
              "      <td>94.2207</td>\n",
              "      <td>538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>96.7878</td>\n",
              "      <td>99.1342</td>\n",
              "      <td>97.947</td>\n",
              "      <td>1145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>97.9104</td>\n",
              "      <td>95.0725</td>\n",
              "      <td>96.4706</td>\n",
              "      <td>328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>98.2759</td>\n",
              "      <td>96.6102</td>\n",
              "      <td>97.4359</td>\n",
              "      <td>285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>94.217</td>\n",
              "      <td>95.7096</td>\n",
              "      <td>94.9574</td>\n",
              "      <td>1450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>81.0018</td>\n",
              "      <td>82.7199</td>\n",
              "      <td>81.8519</td>\n",
              "      <td>1326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>89.1655</td>\n",
              "      <td>93.905</td>\n",
              "      <td>91.4739</td>\n",
              "      <td>1325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>86.7102</td>\n",
              "      <td>86.9945</td>\n",
              "      <td>86.8522</td>\n",
              "      <td>796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>92.1502</td>\n",
              "      <td>65.3753</td>\n",
              "      <td>76.4873</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>94.4444</td>\n",
              "      <td>86.9318</td>\n",
              "      <td>90.5325</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>93.2203</td>\n",
              "      <td>83.9695</td>\n",
              "      <td>88.3534</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>29</td>\n",
              "      <td>94.7883</td>\n",
              "      <td>92.0886</td>\n",
              "      <td>93.4189</td>\n",
              "      <td>291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>30</td>\n",
              "      <td>69.0909</td>\n",
              "      <td>74.5098</td>\n",
              "      <td>71.6981</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>31</td>\n",
              "      <td>66.1157</td>\n",
              "      <td>77.6699</td>\n",
              "      <td>71.4286</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>32</td>\n",
              "      <td>69.7368</td>\n",
              "      <td>59.5506</td>\n",
              "      <td>64.2424</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>33</td>\n",
              "      <td>85</td>\n",
              "      <td>50</td>\n",
              "      <td>62.963</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>34</td>\n",
              "      <td>93.346</td>\n",
              "      <td>87.3665</td>\n",
              "      <td>90.2574</td>\n",
              "      <td>491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>35</td>\n",
              "      <td>83.3333</td>\n",
              "      <td>55.5556</td>\n",
              "      <td>66.6667</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>36</td>\n",
              "      <td>100</td>\n",
              "      <td>75</td>\n",
              "      <td>85.7143</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>37</td>\n",
              "      <td>90.1786</td>\n",
              "      <td>99.0196</td>\n",
              "      <td>94.3925</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>38</td>\n",
              "      <td>57.5</td>\n",
              "      <td>58.9744</td>\n",
              "      <td>58.2278</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>39</td>\n",
              "      <td>68.9873</td>\n",
              "      <td>77.8571</td>\n",
              "      <td>73.1544</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>40</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>41</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>42</td>\n",
              "      <td>100</td>\n",
              "      <td>88.2353</td>\n",
              "      <td>93.75</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>43</td>\n",
              "      <td>50</td>\n",
              "      <td>11.1111</td>\n",
              "      <td>18.1818</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>45</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>46</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>accuracy=93.06</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               tag precision   recall  f_score correct_count\n",
              "0                1   99.8641  99.7015  99.7827          3674\n",
              "1                2    94.681  94.0955  94.3874          7761\n",
              "2                3   90.7904  96.3704  93.4972         16276\n",
              "3                4   99.9146   99.644  99.7791         12876\n",
              "4                5   91.6667  98.5075   94.964            66\n",
              "5                6   99.1561  90.0383  94.3775           470\n",
              "6                7   97.6654  96.5849  97.1221          2008\n",
              "7                8   76.5957  52.0482  61.9799           216\n",
              "8                9   58.7302  60.3261  59.5174           222\n",
              "9               10   61.8214  42.0739  50.0709           353\n",
              "10              11   80.3738      100  89.1192            86\n",
              "11              12   95.0182   97.628  96.3054           782\n",
              "12              13   89.1701  84.3072  86.6705          3030\n",
              "13              14   93.4845  94.6256  94.0516          5194\n",
              "14              15   80.5031  68.4492  73.9884           768\n",
              "15              16    90.031  84.5962   87.229          2032\n",
              "16              17   96.4158  92.1233  94.2207           538\n",
              "17              18   96.7878  99.1342   97.947          1145\n",
              "18              19   97.9104  95.0725  96.4706           328\n",
              "19              20   98.2759  96.6102  97.4359           285\n",
              "20              21    94.217  95.7096  94.9574          1450\n",
              "21              22   81.0018  82.7199  81.8519          1326\n",
              "22              23   89.1655   93.905  91.4739          1325\n",
              "23              24   86.7102  86.9945  86.8522           796\n",
              "24              25   92.1502  65.3753  76.4873           270\n",
              "25              26   94.4444  86.9318  90.5325           153\n",
              "26              27   93.2203  83.9695  88.3534           110\n",
              "27              29   94.7883  92.0886  93.4189           291\n",
              "28              30   69.0909  74.5098  71.6981            76\n",
              "29              31   66.1157  77.6699  71.4286            80\n",
              "30              32   69.7368  59.5506  64.2424           106\n",
              "31              33        85       50   62.963            34\n",
              "32              34    93.346  87.3665  90.2574           491\n",
              "33              35   83.3333  55.5556  66.6667             5\n",
              "34              36       100       75  85.7143            12\n",
              "35              37   90.1786  99.0196  94.3925           101\n",
              "36              38      57.5  58.9744  58.2278            23\n",
              "37              39   68.9873  77.8571  73.1544           109\n",
              "38              40       100      100      100           280\n",
              "39              41        80       80       80            16\n",
              "40              42       100  88.2353    93.75            15\n",
              "41              43        50  11.1111  18.1818             1\n",
              "42              45         -        0        -             0\n",
              "43              46         -        0        -             0\n",
              "44  accuracy=93.06                                          "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 23.5 s, sys: 4.11 s, total: 27.6 s\n",
            "Wall time: 16.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOnHO-__kj7T"
      },
      "source": [
        "\n",
        "### 4.2.2 CRF with pretrained weight\n",
        "\n",
        "### #TODO 2\n",
        "\n",
        "We would like you create a neural CRF POS tagger model  with the pretrained word embedding as an input and the word embedding is trainable (not fixed). To finish this excercise you must train the model and show the evaluation report with this model as shown in the example.\n",
        "\n",
        "Please note that the given pretrained word embedding only have weights for the vocabuary in BEST corpus.\n",
        "\n",
        "Optionally, you can use your own pretrained word embedding.\n",
        "\n",
        "#### Hint: You can get the embedding from get_embeddings function from embeddings/emb_reader.py . \n",
        "\n",
        "(You may want to read about Tensorflow Masking layer and Trainable parameter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5I3gAXSZqQS",
        "outputId": "7d123dfe-d7d9-4f71-eada-0070861ae2e5"
      },
      "source": [
        "from embeddings.emb_reader import get_embeddings\n",
        "pretrained_embeddings = get_embeddings()\n",
        "(hits, misses) = (0, 0)\n",
        "num_tokens = len(word_to_idx)\n",
        "embedding_dim = pretrained_embeddings[list(pretrained_embeddings.keys())[0]].shape[0]\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "\n",
        "for word, i in word_to_idx.items():\n",
        "    embedding_vector = pretrained_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%s misses)\" % (hits, misses))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 3706 words (11313 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVBAv3a9kanH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ee829b-69cd-4b65-bfc2-fac22d98286f"
      },
      "source": [
        "# INSERT YOUR CODE HERE\n",
        "inputs = Input(shape=(102,), dtype='int32')\n",
        "output = (Embedding(num_tokens, embedding_dim,input_length=102,\n",
        "                    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                    trainable=True, mask_zero=True))(inputs)\n",
        "output = Bidirectional(GRU(32, return_sequences=True))(output)\n",
        "output = Dropout(0.2)(output)\n",
        "output = TimeDistributed(Dense(n_classes, activation=None))(output)\n",
        "crf = CRF(dtype='float32')\n",
        "output = crf(output)\n",
        "base_model = Model(inputs, output)\n",
        "model_crf_pre = ModelWithCRFLoss(base_model)\n",
        "model_crf_pre.compile(optimizer=Adam(lr=0.001))\n",
        "\n",
        "model_crf_pre.build((102,1))\n",
        "model_crf_pre.summary()\n",
        "model_crf_pre.fit(x=x_train,y=y_train.argmax(axis=2), batch_size=64,epochs=10,verbose=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 102) for input KerasTensor(type_spec=TensorSpec(shape=(None, 102), dtype=tf.int32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (102, 1).\n",
            "Model: \"model_with_crf_loss_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_5 (Functional)         ((None, 102), (None, 102, 985458    \n",
            "=================================================================\n",
            "Total params: 985,460\n",
            "Trainable params: 985,456\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "290/290 [==============================] - 108s 340ms/step - crf_loss: 21.7243 - accuracy: 0.6452\n",
            "Epoch 2/10\n",
            "290/290 [==============================] - 100s 344ms/step - crf_loss: 4.8584 - accuracy: 0.9195\n",
            "Epoch 3/10\n",
            "290/290 [==============================] - 99s 342ms/step - crf_loss: 3.1912 - accuracy: 0.9425\n",
            "Epoch 4/10\n",
            "290/290 [==============================] - 99s 343ms/step - crf_loss: 2.6055 - accuracy: 0.9507\n",
            "Epoch 5/10\n",
            "290/290 [==============================] - 98s 339ms/step - crf_loss: 2.2992 - accuracy: 0.9545\n",
            "Epoch 6/10\n",
            "290/290 [==============================] - 101s 348ms/step - crf_loss: 2.1139 - accuracy: 0.9578\n",
            "Epoch 7/10\n",
            "290/290 [==============================] - 99s 340ms/step - crf_loss: 1.9828 - accuracy: 0.9597\n",
            "Epoch 8/10\n",
            "290/290 [==============================] - 100s 345ms/step - crf_loss: 1.8823 - accuracy: 0.9613\n",
            "Epoch 9/10\n",
            "290/290 [==============================] - 98s 337ms/step - crf_loss: 1.7697 - accuracy: 0.9632\n",
            "Epoch 10/10\n",
            "290/290 [==============================] - 100s 344ms/step - crf_loss: 1.6935 - accuracy: 0.9647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1def63d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "alrUXBkTYr6t",
        "outputId": "1827a010-f315-424d-e7e8-87347fbd4581"
      },
      "source": [
        "%%time\n",
        "model_crf_pre.save_weights('./data/my_pos_crf_pre.h5')\n",
        "# model_crf_pre.load_weights('./data/my_pos_crf_pre.h5')\n",
        "result = model_crf_pre.predict(x_test) #crf will return 4 items\n",
        "y_pred = result[1]\n",
        "ypred = [outputToLabel(y_pred[i],len(y_test[i])) for i in range(len(y_pred))]\n",
        "evaluation_report(y_test, ypred)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f_score</th>\n",
              "      <th>correct_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>99.8641</td>\n",
              "      <td>99.6744</td>\n",
              "      <td>99.7691</td>\n",
              "      <td>3673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>94.388</td>\n",
              "      <td>94.6169</td>\n",
              "      <td>94.5023</td>\n",
              "      <td>7804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90.4903</td>\n",
              "      <td>96.0625</td>\n",
              "      <td>93.1932</td>\n",
              "      <td>16224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>99.9922</td>\n",
              "      <td>99.6363</td>\n",
              "      <td>99.8139</td>\n",
              "      <td>12875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>88</td>\n",
              "      <td>98.5075</td>\n",
              "      <td>92.9577</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>99.568</td>\n",
              "      <td>88.3142</td>\n",
              "      <td>93.6041</td>\n",
              "      <td>461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>97.2662</td>\n",
              "      <td>97.5469</td>\n",
              "      <td>97.4063</td>\n",
              "      <td>2028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>70.7246</td>\n",
              "      <td>58.7952</td>\n",
              "      <td>64.2105</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>68.9024</td>\n",
              "      <td>61.413</td>\n",
              "      <td>64.9425</td>\n",
              "      <td>226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>61.6088</td>\n",
              "      <td>40.1669</td>\n",
              "      <td>48.6291</td>\n",
              "      <td>337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>83.4951</td>\n",
              "      <td>100</td>\n",
              "      <td>91.0053</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>96.5686</td>\n",
              "      <td>98.377</td>\n",
              "      <td>97.4644</td>\n",
              "      <td>788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>90.3529</td>\n",
              "      <td>85.4758</td>\n",
              "      <td>87.8467</td>\n",
              "      <td>3072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>94.0641</td>\n",
              "      <td>94.1155</td>\n",
              "      <td>94.0898</td>\n",
              "      <td>5166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>83.7752</td>\n",
              "      <td>70.41</td>\n",
              "      <td>76.5133</td>\n",
              "      <td>790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>86.7194</td>\n",
              "      <td>86.7194</td>\n",
              "      <td>86.7194</td>\n",
              "      <td>2083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>97.9592</td>\n",
              "      <td>82.1918</td>\n",
              "      <td>89.3855</td>\n",
              "      <td>480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>96.7089</td>\n",
              "      <td>99.2208</td>\n",
              "      <td>97.9487</td>\n",
              "      <td>1146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>97.6608</td>\n",
              "      <td>96.8116</td>\n",
              "      <td>97.2344</td>\n",
              "      <td>334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>97.6109</td>\n",
              "      <td>96.9492</td>\n",
              "      <td>97.2789</td>\n",
              "      <td>286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>93.655</td>\n",
              "      <td>93.5314</td>\n",
              "      <td>93.5931</td>\n",
              "      <td>1417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>81.1284</td>\n",
              "      <td>78.0412</td>\n",
              "      <td>79.5548</td>\n",
              "      <td>1251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>88.6394</td>\n",
              "      <td>95.1099</td>\n",
              "      <td>91.7607</td>\n",
              "      <td>1342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>94.7433</td>\n",
              "      <td>84.6995</td>\n",
              "      <td>89.4403</td>\n",
              "      <td>775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>89.4081</td>\n",
              "      <td>69.4915</td>\n",
              "      <td>78.2016</td>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>94.8276</td>\n",
              "      <td>93.75</td>\n",
              "      <td>94.2857</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>93.3333</td>\n",
              "      <td>74.8092</td>\n",
              "      <td>83.0508</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>29</td>\n",
              "      <td>94.2249</td>\n",
              "      <td>98.1013</td>\n",
              "      <td>96.124</td>\n",
              "      <td>310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>30</td>\n",
              "      <td>71.1538</td>\n",
              "      <td>72.549</td>\n",
              "      <td>71.8447</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>31</td>\n",
              "      <td>45.8333</td>\n",
              "      <td>85.4369</td>\n",
              "      <td>59.661</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>32</td>\n",
              "      <td>84.6154</td>\n",
              "      <td>55.618</td>\n",
              "      <td>67.1186</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>33</td>\n",
              "      <td>92.1053</td>\n",
              "      <td>51.4706</td>\n",
              "      <td>66.0377</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>34</td>\n",
              "      <td>89.8778</td>\n",
              "      <td>91.637</td>\n",
              "      <td>90.7489</td>\n",
              "      <td>515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>35</td>\n",
              "      <td>50</td>\n",
              "      <td>55.5556</td>\n",
              "      <td>52.6316</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>36</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>37</td>\n",
              "      <td>90.991</td>\n",
              "      <td>99.0196</td>\n",
              "      <td>94.8357</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>38</td>\n",
              "      <td>51.1628</td>\n",
              "      <td>56.4103</td>\n",
              "      <td>53.6585</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>39</td>\n",
              "      <td>80.8824</td>\n",
              "      <td>78.5714</td>\n",
              "      <td>79.7101</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>40</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>41</td>\n",
              "      <td>76.1905</td>\n",
              "      <td>80</td>\n",
              "      <td>78.0488</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>42</td>\n",
              "      <td>100</td>\n",
              "      <td>82.3529</td>\n",
              "      <td>90.3226</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>45</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>46</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>accuracy=93.08</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               tag precision   recall  f_score correct_count\n",
              "0                1   99.8641  99.6744  99.7691          3673\n",
              "1                2    94.388  94.6169  94.5023          7804\n",
              "2                3   90.4903  96.0625  93.1932         16224\n",
              "3                4   99.9922  99.6363  99.8139         12875\n",
              "4                5        88  98.5075  92.9577            66\n",
              "5                6    99.568  88.3142  93.6041           461\n",
              "6                7   97.2662  97.5469  97.4063          2028\n",
              "7                8   70.7246  58.7952  64.2105           244\n",
              "8                9   68.9024   61.413  64.9425           226\n",
              "9               10   61.6088  40.1669  48.6291           337\n",
              "10              11   83.4951      100  91.0053            86\n",
              "11              12   96.5686   98.377  97.4644           788\n",
              "12              13   90.3529  85.4758  87.8467          3072\n",
              "13              14   94.0641  94.1155  94.0898          5166\n",
              "14              15   83.7752    70.41  76.5133           790\n",
              "15              16   86.7194  86.7194  86.7194          2083\n",
              "16              17   97.9592  82.1918  89.3855           480\n",
              "17              18   96.7089  99.2208  97.9487          1146\n",
              "18              19   97.6608  96.8116  97.2344           334\n",
              "19              20   97.6109  96.9492  97.2789           286\n",
              "20              21    93.655  93.5314  93.5931          1417\n",
              "21              22   81.1284  78.0412  79.5548          1251\n",
              "22              23   88.6394  95.1099  91.7607          1342\n",
              "23              24   94.7433  84.6995  89.4403           775\n",
              "24              25   89.4081  69.4915  78.2016           287\n",
              "25              26   94.8276    93.75  94.2857           165\n",
              "26              27   93.3333  74.8092  83.0508            98\n",
              "27              29   94.2249  98.1013   96.124           310\n",
              "28              30   71.1538   72.549  71.8447            74\n",
              "29              31   45.8333  85.4369   59.661            88\n",
              "30              32   84.6154   55.618  67.1186            99\n",
              "31              33   92.1053  51.4706  66.0377            35\n",
              "32              34   89.8778   91.637  90.7489           515\n",
              "33              35        50  55.5556  52.6316             5\n",
              "34              36       100      100      100            16\n",
              "35              37    90.991  99.0196  94.8357           101\n",
              "36              38   51.1628  56.4103  53.6585            22\n",
              "37              39   80.8824  78.5714  79.7101           110\n",
              "38              40       100      100      100           280\n",
              "39              41   76.1905       80  78.0488            16\n",
              "40              42       100  82.3529  90.3226            14\n",
              "41              43         0        0        -             0\n",
              "42              45         -        0        -             0\n",
              "43              46         -        0        -             0\n",
              "44  accuracy=93.08                                          "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24 s, sys: 4.19 s, total: 28.2 s\n",
            "Wall time: 17.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYX749sbkzA-"
      },
      "source": [
        "### #TODO 3\n",
        "Compare the result between all neural tagger models in 4.1 and 4.2.x and provide a convincing reason and example for the result of these models (which model perform better, why?)\n",
        "\n",
        "(If you use your own weight please state so in the answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJKtOsoRhHQv"
      },
      "source": [
        "<b>Write your answer here :</b>\n",
        "\n",
        "There is 3 methods in this experiment to perform in PoS tagging task which are \"nn\", \"nn_crf\", and \"nn_crf with pretrained weight\".\n",
        "\n",
        "Accuracy:\n",
        "\n",
        "    - acc of nn: 93.02%                                    [with epoch=20]\n",
        "    - acc of nn_crf: \n",
        "        - 93.06%                                           [with epoch=20]\n",
        "        - 92.30%                                           [with epoch=30 the acc is decrease -> overfit]\n",
        "    - acc of nn_crf with pretrained weight: 93.08%         [with epoch=10 training more than this will make acc drop in my experiment.]\n",
        "\n",
        "    summary: nn_crf with pretrained > nn_crf > nn . (however they are diffrent a bit < 0.4%)\n",
        "\n",
        "Training time:\n",
        "\n",
        "    - nn: 20 epoch (each epoch=7 sec)                       -> cost 20x7 = \"140 sec\"\n",
        "    - nn_crf: 20 epoch (each epoch=100 sec)                 -> cost 20*100 = \"2000 sec\"\n",
        "    - nn_crf with pretrained: 10 epoch (each epoch=100 sec) -> cost 10*100 = \"1000 sec\"\n",
        "\n",
        "    summary: nn <<< nn_crf with pretrained << nn_crf (in this experiment) -> all model have nearly acc.\n",
        "\n",
        "Model Speed:\n",
        "    \n",
        "    we will compare this part by using wall time while predicting of the model to compare speed of the model\n",
        "\n",
        "    - nn:                                                    3.71 sec\n",
        "    - nn_crf:                                                16.9 sec\n",
        "    - nn_crf with pretrained:                                17.3 sec\n",
        "\n",
        "     summary: nn <<< nn_crf = nn_crf with pretrained(equal model size)\n",
        "    \n",
        "\n",
        "\n",
        "Summary: \n",
        "for my point of view, I will choose nn model because nn give the reasonable accuracy with faster training and faster model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z8raWOawjxp"
      },
      "source": [
        "### #TODO 4\n",
        "\n",
        "Upon inference, the model also returns its transition matrix, which is learned during training. Your task is to observe and report whether the returned matrix is sensible. You can provide some examples to support your argument.\n",
        "\n",
        "#### Hint : The transition matrix must have the shape  of (num_class, num_class).\n",
        "\n",
        "<b>Write your answer here :</b>\n",
        "\n",
        "About transition matrix:\n",
        "\n",
        "- Transition matrix will have size of (n_classes,n_classes). In this case it will be (48,48).\n",
        "\n",
        "- The transition matrix will have row(i) and column(j). While reading the transition matrix, you should look at row(i) first and then follow with column(j). So it means that the transition score you get is the transition score from tag i to tag j.\n",
        "    \n",
        "- The transition score is the score that model learn from the data:\n",
        "  - if tag i appear, tag j have a high chance to appear after it. So the model will give high the transition score from tag i to tag j.\n",
        "  - Opposite to the high score, if the model give the low transition score to that pair of tag, it means that tag j usually not appear after tag i.\n",
        "\n",
        "Analysis:  \n",
        "- As you can see from the heatmap of transition matrix below,\n",
        "    - the bright spot means that the transition score is high.\n",
        "    - the dark spot means that the transition sccore is low.\n",
        "\n",
        "- So, I pick about 3 bright spot(high transition score) to analysis and all of them seem reasonable.\n",
        "    1.   from NTTL(Title noun) to NPRP(Proper noun) which seem resonable because title of noun (such as ดร.) must follow with proper noun.\n",
        "    2.   from FIXV(Adverbial prefix) to VSTA(Stative verb) which seem ืreasonable because Adverbial prefix(such as อย่าง) usually follow with stative verb(such as ชอบ รัก) but not match with some stative verb (such as เห็น รู้).\n",
        "    3.   from FIXV(Adverbial prefix) to VATT(Attributive verb) which seem ืreasonable because Adverbial prefix(such as อย่าง) usually follow with attributive verb(such as อ้วน ดี สวย).\n",
        "\n",
        "- Then, I pick about 3 dark spot(low transition score) to analysis and all of them seem reasonable.\n",
        "    1.   from FIXV(Adverbial prefix) to NCMN(Cardinal number) which is seems reasonable because adverbial prefix(such as อย่าง) should not follow with cardinal number(such as 1 2).\n",
        "    2.   from CNIT(Unit classifier) to NPRP(Proper noun) which is seems reasonable because unit classifier(such as ตัว เล่ม) should not follow with proper noun.\n",
        "    3.   from XVAE(Post-verb auxiliary) to DDAQ(Definite determiner  following quantitative expression) which is seems reasonable because post-verb auxiliary(such as ไป ขึ้น) should not follow with DDAQ(such as พอดี ถ้วน)\n",
        "\n",
        "summary: I think that the transition matrix seems sensible with all reasons above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKXFBcECNfxL",
        "outputId": "02767b79-caa6-4114-87d1-fad4312e2725"
      },
      "source": [
        "transition_matrix = crf.transitions.numpy()\n",
        "print('transition matrix shape:',transition_matrix.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "transition matrix shape: (48, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRgJBoJIKVUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606bf899-4f1e-46a8-f6df-7881edee3150"
      },
      "source": [
        "transition_matrix"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.10593769, -0.03279777, -0.37488276, ...,  0.15101498,\n",
              "         0.3019332 , -0.20515718],\n",
              "       [-0.14785716, -0.4685588 ,  0.09250808, ...,  0.00943844,\n",
              "        -0.13445269, -0.25476408],\n",
              "       [-0.12834364,  0.11082927, -0.46854505, ..., -0.26941627,\n",
              "        -0.00110858,  0.17365965],\n",
              "       ...,\n",
              "       [-0.12138613, -0.02356436, -0.13002276, ..., -0.12561345,\n",
              "        -0.34274864, -0.165671  ],\n",
              "       [-0.0289832 , -0.30262512, -0.4335802 , ..., -0.11440538,\n",
              "        -0.03528374, -0.19618472],\n",
              "       [-0.11082111, -0.1415203 , -0.27420795, ...,  0.13307239,\n",
              "        -0.24492078, -0.08499394]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-NnedcYSQ51"
      },
      "source": [
        "tag_list = [0]*(len(label_to_idx)+1)\n",
        "for tag_name,idx in label_to_idx.items():\n",
        "    tag_list[idx] = tag_name"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "hYzDpRU2USjs",
        "outputId": "6875dd87-738d-4096-edcb-3c3a1478341e"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,10)) \n",
        "ax = sns.heatmap(transition_matrix, xticklabels=tag_list, yticklabels=tag_list)\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlGccQsaUh3f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}